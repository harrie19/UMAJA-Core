#!/usr/bin/env python3
"""
Agent-to-Agent Communication Demo
Demonstrates two agents communicating via VectorComm with safety constraints

This example shows:
1. Two agents encoding and exchanging messages
2. Safety polytope filtering unsafe messages
3. Policy enforcement blocking resource violations
4. Audit trail logging all actions
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
from umaja_core.protocols.vectorcomm.encoder import VectorCommEncoder
from umaja_core.protocols.vectorcomm.transport import VectorMessage, VectorTransport
from umaja_core.protocols.safety.polytope import SafetyPolytope
from umaja_core.protocols.enforcement.policy_enforcer import PolicyEnforcer
from umaja_core.protocols.enforcement.audit_trail import AuditTrail
from umaja_core.protocols.ethics.value_embeddings import EthicalValueEncoder


def print_header(text):
    """Print formatted header"""
    print("\n" + "="*70)
    print(f"  {text}")
    print("="*70)


def main():
    """Run A2A communication demo"""
    print_header("UMAJA Vector Meta-Language Protocol - A2A Demo")
    
    print("\nğŸš€ Initializing systems...")
    
    # Initialize encoder (will download models on first run)
    print("   ğŸ“¡ Loading VectorComm Encoder...")
    encoder = VectorCommEncoder()
    print(f"   âœ“ Encoder ready with {len(encoder.TIER_CONFIGS)} tiers")
    
    # Initialize transport
    transport = VectorTransport()
    print("   âœ“ Transport layer ready")
    
    # Initialize safety polytope (sphere in embedding space)
    print("   ğŸ›¡ï¸  Creating safety polytope...")
    center = np.zeros(768)  # Tier 2 dimension
    radius = 5.0
    safety = SafetyPolytope.create_sphere_polytope(center, radius, n_constraints=50)
    print(f"   âœ“ Safety polytope created with {len(safety.constraints)} constraints")
    
    # Initialize policy enforcer
    print("   ğŸ“‹ Loading resource policy...")
    enforcer = PolicyEnforcer()
    policy_path = Path(__file__).parent / "resource_policy.xml"
    if policy_path.exists():
        policy = enforcer.load_policy(str(policy_path))
        print(f"   âœ“ Policy loaded: CPU limit={policy.limits.cpu_max}%")
    else:
        print("   âš ï¸  Policy file not found, skipping policy enforcement")
        enforcer = None
    
    # Initialize audit trail
    audit = AuditTrail()
    print("   âœ“ Audit trail initialized")
    
    # Initialize ethical value encoder
    print("   ğŸ¯ Loading ethical value encoder...")
    ethics = EthicalValueEncoder()
    print("   âœ“ Ethics encoder ready")
    
    print("\n" + "="*70)
    print("\nğŸ“¨ SCENARIO 1: Safe message transmission")
    print("-" * 70)
    
    # Agent 1 sends safe message
    message1 = "Hello Agent 2, let's collaborate on this task"
    print(f"\nğŸ¤– Agent 1: '{message1}'")
    
    print("   â³ Encoding message (Tier 2: 768D)...")
    vector1 = encoder.encode(message1, tier=2)
    print(f"   âœ“ Encoded to {len(vector1)}D vector")
    
    print("   ğŸ›¡ï¸  Checking safety constraints...")
    is_safe = safety.is_safe(vector1, check_margin=False)
    print(f"   {'âœ“' if is_safe else 'âœ—'} Safety check: {'PASSED' if is_safe else 'FAILED'}")
    
    if not is_safe:
        print("   ğŸ”§ Steering to safe region...")
        vector1 = safety.steer_to_safe(vector1)
        print("   âœ“ Vector corrected to safe region")
    
    # Create and send message
    msg1 = VectorMessage(
        sender_id="agent1",
        receiver_id="agent2",
        vector=vector1,
        tier=2,
        metadata={'text': message1}
    )
    
    transport.send(msg1)
    print(f"   ğŸ“¤ Message sent to Agent 2")
    
    # Log to audit trail
    audit.log_action(
        agent_id="agent1",
        action={'action_type': 'send_message', 'message_id': msg1.message_id},
        compliant=True
    )
    
    # Agent 2 receives message
    print("\nğŸ¤– Agent 2: Receiving message...")
    received = transport.receive("agent2")
    if received:
        print(f"   âœ“ Received message from {received.sender_id}")
        print(f"   ğŸ“Š Vector dimension: {len(received.vector)}")
        print(f"   ğŸ·ï¸  Metadata: {received.metadata}")
    
    print("\n" + "="*70)
    print("\nğŸ“¨ SCENARIO 2: Resource-violating action blocked")
    print("-" * 70)
    
    if enforcer:
        print("\nğŸ¤– Agent 3: Attempting high-resource action...")
        action3 = {
            'cpu_usage': '95%',  # Exceeds 80% limit
            'memory_usage': '8GB',
            'action_type': 'heavy_computation'
        }
        print(f"   Requested: CPU={action3['cpu_usage']}, Memory={action3['memory_usage']}")
        
        print("   ğŸ“‹ Checking policy compliance...")
        result = enforcer.enforce_limits(action3)
        
        if result.allowed:
            print("   âœ“ Action ALLOWED")
        else:
            print(f"   âœ— Action BLOCKED: {result.reason}")
        
        # Log to audit
        audit.log_action(
            agent_id="agent3",
            action=action3,
            compliant=result.allowed
        )
    
    print("\n" + "="*70)
    print("\nğŸ“¨ SCENARIO 3: Ethical alignment check")
    print("-" * 70)
    
    print("\nğŸ¤– Agent 4: Checking ethical alignment...")
    action_text = "Share resources fairly with all agents"
    value_text = "fairness and cooperation"
    
    print(f"   Action: '{action_text}'")
    print(f"   Target value: '{value_text}'")
    
    print("   â³ Encoding action and value...")
    action_vector = encoder.encode(action_text, tier=2)
    value_vector = ethics.encode_value(value_text)
    
    print("   ğŸ¯ Computing alignment score...")
    alignment = ethics.compute_alignment_score(action_vector, value_vector)
    print(f"   âœ“ Alignment score: {alignment:.3f}")
    
    if alignment > 0.5:
        print(f"   âœ… Action is well-aligned with target value")
    else:
        print(f"   âš ï¸  Action has low alignment with target value")
    
    print("\n" + "="*70)
    print("\nğŸ“Š AUDIT TRAIL SUMMARY")
    print("-" * 70)
    
    print("\n   ğŸ” Verifying chain integrity...")
    is_valid = audit.verify_chain_integrity()
    print(f"   {'âœ“' if is_valid else 'âœ—'} Chain integrity: {'VALID' if is_valid else 'INVALID'}")
    
    stats = audit.get_statistics()
    print(f"\n   ğŸ“ˆ Statistics:")
    print(f"      Total actions: {stats['total_actions']}")
    print(f"      Compliant: {stats['compliant_actions']}")
    print(f"      Non-compliant: {stats['non_compliant_actions']}")
    print(f"      Compliance rate: {stats['compliance_rate']:.1%}")
    print(f"      Unique agents: {stats['unique_agents']}")
    
    print("\n   ğŸ“‹ Recent audit entries:")
    for i, entry in enumerate(audit.entries[-3:], 1):
        status = "âœ“" if entry.compliant else "âœ—"
        print(f"      {status} {entry.agent_id}: {entry.action.get('action_type', 'unknown')}")
    
    print("\n" + "="*70)
    print("\nâœ… DEMO COMPLETE")
    print("\nKey accomplishments:")
    print("  âœ“ Encoded and transmitted vector messages between agents")
    print("  âœ“ Enforced geometric safety constraints on embeddings")
    print("  âœ“ Blocked policy-violating actions")
    print("  âœ“ Verified ethical alignment of actions")
    print("  âœ“ Maintained tamper-evident audit trail")
    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Demo interrupted by user")
    except Exception as e:
        print(f"\n\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
